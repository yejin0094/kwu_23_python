# LLM(Large Language Model) 소개
# - 거대 언어 모델(데이터 크기 ↑, 모델 크기 ↑)
# - 종류: GPT(Open AI), Gemini, Claude(Anthropic-공학이나 수학용), Grok(일론XAI), Llama(meta), [엑사원(LG), 솔라(업스테이지) - 관공서용]
# - ex: ChatGPT
#        ㄴ GPT 모델을 Chat을 통해서 사용할 수 있게 개발 된 서비스
# - 현재는 LLM의 시대라서, 소규모 언어모델을 잘 사용하지 않음(특정한 상황을 제외하고!)
#   -> LLM을 사용 -> GPT LLM 1번 학습하는 데 약 1조 소요
#   -> 일반 중소기업에서 LLM을 직접 개발하는 것은 현실적으로 불가능
#   -> 일반 회사들은 직접 개발은 비효율적
#   -> 일반 회사들은 잘 만들어진 LLM을 빌려서 개발(사용한만큼 금액을 지불)


# LLM은 일반적인 데이터로 학습
#   ㄴ 일반적인 질문 -> 답변을 아주 잘함
#   ㄴ 특별한 질문(학습하지 않은 질문) -> 거짓말(환각현상: 할루시네이션)
#   ㄴ LLM이 특별한 질문도 답변할 수 있도록 변경
#       ㄴ 1. 프롬프트 엔지니어링 + RAG = Retrieval(검색)-Augmented(증강) Generation(세대) (기업에서 선호, 비용이 적게 들음)
#       ㄴ 2. 직접 LLM모델을 운영 + 파인튜닝 (대기업에서 선호, 비용이 많이 듬, 고급기술)

# --------------------------------------------------------------------------------------------
# <RAG = Retrieval-Augmented Generation>
# -> "검색 + LLM" 방식
# - 비유하자면 LLM은 큰 '두뇌', RAG는 그 두뇌 옆에 있는 '도서관 검색기'
# LLM이 모르는 질문을 받으면
# 직접 학습한 척하는 게 아니라 외부 자료(문서, PDF, DB)를 찾아보고 그 내용을 토대로 답을 만들줌

# <왜 비용이 적게 드는가?>
# 1) 모델을 다시 학습시키지 않기 때문에
#  - LLM을 새로 학습(파인튜닝)시키는 것은 GPU 여러 대가 필요하고 매우 비싸요
#  - RAG는 그냥 '검색만 추가'하면 끝이라 비용이 거의 없음
# 2) 필요한 건 문서 저장 비용 정도
#  - PDF, 텍스트를 "벡터DB"에 넣고 검색하면 끝
#  - GPU를 오래 돌릴 필요가 없어서 비용이 매우 적음
# 3) 모델이 커지지 않음
#  - 모델 파라미터를 바꾸지 않음 -> 유지비 ↓

# <RAG는 어디에 쓰는가?>
# [RAG는 "많이 바뀌는 정보"에 적합함]
# - 회사 매뉴얼
# - 최신 고객 데이터
# - 제품 설명서
# - 자주 바뀌는 규정/정책
# - 법률/의학 문서 검색 기반 답변
# - 기업 내부 챗봇
# 즉,
# 〓▶ "모델이 모르는 내용을 즉석에서 찾아서 답해야 할 때"
# --------------------------------------------------------------------------------------------
# <파인튜닝(Fine-tuning)은 뭐고, 왜 비싼가?>
# 파인튜닝 = LLM의 뇌 구조를 직접 바꾸는 것
# RAG는 검색을 추가하는 것이었다면, 파인튜닝은 모델 자체의 '성격과 능력'을 바꾸는 작업

# <왜 비싼가?>
# 1) GPU 비용이 매우 큼
# - 파인튜닝은 모델 수백억 개의 파라미터를 다시 학습해야 함.
# - GPU 8~46개를 며칠씩 돌리기도 함 -> 비용 ↑↑↑
# 2) 데이터 정제 + 라벨링 비용
# - 잘 정리된 학습 데이터를 많이 넣어야 함
# - 사람에게 돈 주고 라벨링하는 경우도 많음 -> 비용 ↑
# 3) 모델을 계속 관리해야 함
# - 오류 나면 다시 학습해야 함 -> 유지비 ↑

# <파인튜닝은 어디에 쓰는가?>
# [특정 능력을 모델에 완전히 심고 싶을 때]
# 회사 맞춤 말투를 아예 몸에 익히기
# 산업 특화 모델 만들기(의료, 법률 전문 AI)
# 특정 스타일 글쓰기 훈련
# 질답 패턴을 학습시켜 챗봇 성향 고정
# 사용자 데이터 기반 정밀 추천 모델

# <이런 게 필요할 때 파인튜닝을 사용>
# 하루에 10만 명 사용
# 빠른 응답
# 매우 특정한 답변 스타일 
# --------------------------------------------------------------------------------------------
# RAG = 검색해서 공부한 다음 설명하는 "학생"
# 파인튜닝 = 뇌를 새로 설계해서 천재로 만드는 "유전자 조작"
# --------------------------------------------------------------------------------------------

# 숙제
# 아이디어: 어떤 AI 챗봇을 만들것인가? 교육용, 업무용, 취미용, 상담용, 기타
#   ㄴ교육용 튜터 챗봇
#      ㄴ 어떤 과목?
#        ㄴ 대상? 중학생 or 고등학생
# ㄴ 챗봇에 들어갈 아이콘도 고민하기(픽셀형식일지...)
# ㄴ 대표색상(+ 2가지 보조색상 + 배경 색상) (**LOL Colors사이트, RGB 색상표, color space사이트, CSS그라디언트사이트 참고)
# ㄴ 웹폰트(글꼴)가져오기 (** Google Fonts사이트 참고) - 5개정도 골라오기


#   ㄴ 목적: 누구를 위한 챗봇인가?

# 11월 3일
# 빌려서 GPT API 사용해보기
# ㄴ 사용한만큼 비용지불
# ㄴ platform.openai.com -> 로그인 -> 카드등록($5) -> API Key 발급
# ㄴ API-Key를 통해서 GPT에게 답변을 생성해달라고 요청!
# ㄴ API-Key 절대 유출되면 안돼요!(보안 중요)

# github(private으로 올려야 우리팀원만 볼 수 있음, 절대 public쓰면 모두에게 공유되기 때문에 회사의 자산이 노출됨)는 온라인에 올리고 gitlab은 우리회사만 관리


